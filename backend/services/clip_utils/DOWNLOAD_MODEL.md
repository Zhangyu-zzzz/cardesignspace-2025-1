# CLIP æ¨¡å‹æ–‡ä»¶ä¸‹è½½è¯´æ˜

## ğŸ“¦ æ¨¡å‹æ–‡ä»¶æœªåŒ…å«åœ¨ä»“åº“ä¸­

ç”±äºCLIPæ¨¡å‹æ–‡ä»¶è¾ƒå¤§ï¼ˆçº¦1.7GBï¼‰ï¼ŒæœªåŒ…å«åœ¨Gitä»“åº“ä¸­ã€‚

## ğŸ”½ å¦‚ä½•è·å–æ¨¡å‹

### æ–¹æ³•1: è‡ªåŠ¨ä¸‹è½½ï¼ˆæ¨èï¼‰

è¿è¡Œä»¥ä¸‹å‘½ä»¤ï¼Œæ¨¡å‹ä¼šè‡ªåŠ¨ä» Hugging Face ä¸‹è½½ï¼š

```bash
cd backend/services/clip_utils
python3 clip_encoder.py
```

é¦–æ¬¡è¿è¡Œæ—¶ï¼Œç¨‹åºä¼šè‡ªåŠ¨ä¸‹è½½ `openai/clip-vit-base-patch32` æ¨¡å‹åˆ°å½“å‰ç›®å½•ã€‚

### æ–¹æ³•2: æ‰‹åŠ¨ä¸‹è½½

1. è®¿é—® Hugging Face: https://huggingface.co/openai/clip-vit-base-patch32
2. ä¸‹è½½æ‰€æœ‰æ¨¡å‹æ–‡ä»¶åˆ° `backend/services/clip_utils/clip-vit-base-patch32/` ç›®å½•
3. ç¡®ä¿åŒ…å«ä»¥ä¸‹æ–‡ä»¶ï¼š
   - `pytorch_model.bin` (577MB)
   - `config.json`
   - `tokenizer.json`
   - `vocab.json`
   - ç­‰å…¶ä»–é…ç½®æ–‡ä»¶

## ğŸ“ æ¨¡å‹ç›®å½•ç»“æ„

```
backend/services/clip_utils/
â”œâ”€â”€ clip_encoder.py
â”œâ”€â”€ config.py
â”œâ”€â”€ DOWNLOAD_MODEL.md  (æœ¬æ–‡ä»¶)
â””â”€â”€ clip-vit-base-patch32/  (éœ€è¦ä¸‹è½½)
    â”œâ”€â”€ pytorch_model.bin
    â”œâ”€â”€ config.json
    â”œâ”€â”€ tokenizer.json
    â””â”€â”€ ...
```

## âš ï¸ æ³¨æ„äº‹é¡¹

- æ¨¡å‹æ–‡ä»¶å·²æ·»åŠ åˆ° `.gitignore`ï¼Œä¸ä¼šè¢«æäº¤åˆ°Git
- ç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´ï¼ˆè‡³å°‘2GBï¼‰
- ä¸‹è½½å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…
- æ¨¡å‹æ–‡ä»¶ä»…åœ¨**é¦–æ¬¡ä½¿ç”¨æ—¶**éœ€è¦ä¸‹è½½

## ğŸš€ éªŒè¯æ¨¡å‹æ˜¯å¦æ­£ç¡®

è¿è¡Œæµ‹è¯•è„šæœ¬ï¼š

```bash
cd backend/services
python3 clip_vectorize_standalone.py "red sports car"
```

å¦‚æœè¾“å‡ºå‘é‡æ•°ç»„ï¼Œè¯´æ˜æ¨¡å‹é…ç½®æ­£ç¡®ã€‚

